# -*- coding: utf-8 -*-
"""Quora_Project_PART2(MlOPS_TEAM_7).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j30Q8VygXffAg6lsF4whY_XWNeGAje-b
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

feature_df = pd.read_csv('feature_df.csv')

feature_df.isnull().sum()

final_df = feature_df.drop(columns=['Unnamed: 0','id','qid1','qid2','Clean_q1_lem','Clean_q2_lem'])
print(final_df.shape)
final_df.head()

final_df.isnull().sum()

ques_df = feature_df[['Clean_q1_lem','Clean_q2_lem']]
ques_df.head()

ques_df_bow=ques_df

ques_df_tfidf=ques_df

ques_df_w2v=ques_df

ques_df_glove=ques_df

ques_df_bert=ques_df

questions= ques_df['Clean_q1_lem']+ques_df['Clean_q2_lem']

from sklearn.feature_extraction.text import CountVectorizer
# merge texts
questions = list(ques_df['Clean_q1_lem']) + list(ques_df['Clean_q2_lem'])

cv = CountVectorizer(max_features=3000)
q1_arr, q2_arr = np.vsplit(cv.fit_transform(questions).toarray(),2)

temp_df1 = pd.DataFrame(q1_arr, index= ques_df.index)
temp_df2 = pd.DataFrame(q2_arr, index= ques_df.index)
temp_df = pd.concat([temp_df1, temp_df2], axis=1)
temp_df.shape

final_df = pd.concat([final_df, temp_df], axis=1)
print(final_df.shape)
final_df.head()

final_df_bow=final_df

final_df_tfidf=final_df

final_df_w2v=final_df

final_df_glove=final_df

final_df_bert=final_df

"""# **Data Preparation - Split the data into train and test set**"""

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(final_df.iloc[:,1:].values,final_df.iloc[:,0].values,test_size=0.2,random_state=1)

X_train

X_test

"""# ML-FLow"""

!pip install mlflow

import mlflow

mlflow.set_tracking_uri("sqlite:///mlflow.db")

mlflow.set_experiment("Quora Question Pair Similarity")

from sklearn.linear_model import LogisticRegression

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
rf = RandomForestClassifier()
rf.fit(X_train,y_train)
y_pred = rf.predict(X_test)
accuracy_score(y_test,y_pred)

!pip install xgboost

from xgboost import XGBClassifier
xgb = XGBClassifier()
xgb.fit(X_train,y_train)
y_pred1 = xgb.predict(X_test)
accuracy_score(y_test,y_pred1)

from sklearn.metrics import confusion_matrix

# for random forest model
confusion_matrix(y_test,y_pred)

# for random forest model
confusion_matrix(y_test,y_pred1)

def test_common_words(q1,q2):
    w1 = set(map(lambda word: word.lower().strip(), q1.split(" ")))
    w2 = set(map(lambda word: word.lower().strip(), q2.split(" ")))    
    return len(w1 & w2)

def test_total_words(q1,q2):
    w1 = set(map(lambda word: word.lower().strip(), q1.split(" ")))
    w2 = set(map(lambda word: word.lower().strip(), q2.split(" ")))    
    return (len(w1) + len(w2))

def test_fetch_token_features(q1,q2):
    
    SAFE_DIV = 0.0001 

    STOP_WORDS = stopwords.words("english")
    
    token_features = [0.0]*8
    
    # Converting the Sentence into Tokens: 
    q1_tokens = q1.split()
    q2_tokens = q2.split()
    
    if len(q1_tokens) == 0 or len(q2_tokens) == 0:
        return token_features

    # Get the non-stopwords in Questions
    q1_words = set([word for word in q1_tokens if word not in STOP_WORDS])
    q2_words = set([word for word in q2_tokens if word not in STOP_WORDS])
    
    #Get the stopwords in Questions
    q1_stops = set([word for word in q1_tokens if word in STOP_WORDS])
    q2_stops = set([word for word in q2_tokens if word in STOP_WORDS])
    
    # Get the common non-stopwords from Question pair
    common_word_count = len(q1_words.intersection(q2_words))
    
    # Get the common stopwords from Question pair
    common_stop_count = len(q1_stops.intersection(q2_stops))
    
    # Get the common Tokens from Question pair
    common_token_count = len(set(q1_tokens).intersection(set(q2_tokens)))
    
    
    token_features[0] = common_word_count / (min(len(q1_words), len(q2_words)) + SAFE_DIV)
    token_features[1] = common_word_count / (max(len(q1_words), len(q2_words)) + SAFE_DIV)
    token_features[2] = common_stop_count / (min(len(q1_stops), len(q2_stops)) + SAFE_DIV)
    token_features[3] = common_stop_count / (max(len(q1_stops), len(q2_stops)) + SAFE_DIV)
    token_features[4] = common_token_count / (min(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)
    token_features[5] = common_token_count / (max(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)
    
    # Last word of both question is same or not
    token_features[6] = int(q1_tokens[-1] == q2_tokens[-1])
    
    # First word of both question is same or not
    token_features[7] = int(q1_tokens[0] == q2_tokens[0])
    
    return token_features

def test_fetch_length_features(q1,q2):
    
    length_features = [0.0]*3
    
    # Converting the Sentence into Tokens: 
    q1_tokens = q1.split()
    q2_tokens = q2.split()
    
    if len(q1_tokens) == 0 or len(q2_tokens) == 0:
        return length_features
    
    # Absolute length features
    length_features[0] = abs(len(q1_tokens) - len(q2_tokens))
    
    #Average Token Length of both Questions
    length_features[1] = (len(q1_tokens) + len(q2_tokens))/2
    
    strs = list(distance.lcsubstrings(q1, q2))
    length_features[2] = len(strs[0]) / (min(len(q1), len(q2)) + 1)
    
    return length_features

def test_fetch_fuzzy_features(q1,q2):
    
    fuzzy_features = [0.0]*4
    
    # fuzz_ratio
    fuzzy_features[0] = fuzz.QRatio(q1, q2)

    # fuzz_partial_ratio
    fuzzy_features[1] = fuzz.partial_ratio(q1, q2)

    # token_sort_ratio
    fuzzy_features[2] = fuzz.token_sort_ratio(q1, q2)

    # token_set_ratio
    fuzzy_features[3] = fuzz.token_set_ratio(q1, q2)

    return fuzzy_features

def query_point_creator(q1,q2):
    
    input_query = []
    
    # preprocess
    q1 = preprocess(q1,'lem')
    q2 = preprocess(q2,'lem')
    
    # fetch basic features
    input_query.append(len(q1))
    input_query.append(len(q2))
    
    input_query.append(len(q1.split(" ")))
    input_query.append(len(q2.split(" ")))
    
    input_query.append(test_common_words(q1,q2))
    input_query.append(test_total_words(q1,q2))
    input_query.append(round(test_common_words(q1,q2)/test_total_words(q1,q2),2))
    
    # fetch token features
    token_features = test_fetch_token_features(q1,q2)
    input_query.extend(token_features)
    
    # fetch length based features
    length_features = test_fetch_length_features(q1,q2)
    input_query.extend(length_features)
    
    # fetch fuzzy features
    fuzzy_features = test_fetch_fuzzy_features(q1,q2)
    input_query.extend(fuzzy_features)
    
    # bow feature for q1
    q1_bow = cv.transform([q1]).toarray()
    
    # bow feature for q2
    q2_bow = cv.transform([q2]).toarray()
    
    
    
    return np.hstack((np.array(input_query).reshape(1,22),q1_bow,q2_bow))

q1 = 'Where is the capital of India?'
q2 = 'What is the current capital of Pakistan?'
q3 = 'Which city serves as the capital of India?'
q4 = 'What is the business capital of India?'



import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from nltk.stem import WordNetLemmatizer
nltk.download('stopwords')
# Downloading wordnet before applying Lemmatizer
nltk.download('wordnet')
nltk.download('omw-1.4')

## initialise the inbuilt Stemmer
stemmer = PorterStemmer()

## We can also use Lemmatizer instead of Stemmer
lemmatizer = WordNetLemmatizer()

def preprocess(q, flag):
    
    q = str(q).lower().strip()
    
    # Replace certain special characters with their string equivalents
    q = q.replace('%', ' percent')
    q = q.replace('$', ' dollar ')
    q = q.replace('₹', ' rupee ')
    q = q.replace('€', ' euro ')
    q = q.replace('@', ' at ')
    
    # The pattern '[math]' appears around 900 times in the whole dataset.
    q = q.replace('[math]', '')
    
    # Replacing some numbers with string equivalents (not perfect, can be done better to account for more cases)
    q = q.replace(',000,000,000 ', 'b ')
    q = q.replace(',000,000 ', 'm ')
    q = q.replace(',000 ', 'k ')
    q = re.sub(r'([0-9]+)000000000', r'\1b', q)
    q = re.sub(r'([0-9]+)000000', r'\1m', q)
    q = re.sub(r'([0-9]+)000', r'\1k', q)
    
    # Decontracting words
    # https://en.wikipedia.org/wiki/Wikipedia%3aList_of_English_contractions
    # https://stackoverflow.com/a/19794953
    contractions = { 
    "ain't": "am not",
    "aren't": "are not",
    "can't": "can not",
    "can't've": "can not have",
    "'cause": "because",
    "could've": "could have",
    "couldn't": "could not",
    "couldn't've": "could not have",
    "didn't": "did not",
    "doesn't": "does not",
    "don't": "do not",
    "hadn't": "had not",
    "hadn't've": "had not have",
    "hasn't": "has not",
    "haven't": "have not",
    "he'd": "he would",
    "he'd've": "he would have",
    "he'll": "he will",
    "he'll've": "he will have",
    "he's": "he is",
    "how'd": "how did",
    "how'd'y": "how do you",
    "how'll": "how will",
    "how's": "how is",
    "i'd": "i would",
    "i'd've": "i would have",
    "i'll": "i will",
    "i'll've": "i will have",
    "i'm": "i am",
    "i've": "i have",
    "isn't": "is not",
    "it'd": "it would",
    "it'd've": "it would have",
    "it'll": "it will",
    "it'll've": "it will have",
    "it's": "it is",
    "let's": "let us",
    "ma'am": "madam",
    "mayn't": "may not",
    "might've": "might have",
    "mightn't": "might not",
    "mightn't've": "might not have",
    "must've": "must have",
    "mustn't": "must not",
    "mustn't've": "must not have",
    "needn't": "need not",
    "needn't've": "need not have",
    "o'clock": "of the clock",
    "oughtn't": "ought not",
    "oughtn't've": "ought not have",
    "shan't": "shall not",
    "sha'n't": "shall not",
    "shan't've": "shall not have",
    "she'd": "she would",
    "she'd've": "she would have",
    "she'll": "she will",
    "she'll've": "she will have",
    "she's": "she is",
    "should've": "should have",
    "shouldn't": "should not",
    "shouldn't've": "should not have",
    "so've": "so have",
    "so's": "so as",
    "that'd": "that would",
    "that'd've": "that would have",
    "that's": "that is",
    "there'd": "there would",
    "there'd've": "there would have",
    "there's": "there is",
    "they'd": "they would",
    "they'd've": "they would have",
    "they'll": "they will",
    "they'll've": "they will have",
    "they're": "they are",
    "they've": "they have",
    "to've": "to have",
    "wasn't": "was not",
    "we'd": "we would",
    "we'd've": "we would have",
    "we'll": "we will",
    "we'll've": "we will have",
    "we're": "we are",
    "we've": "we have",
    "weren't": "were not",
    "what'll": "what will",
    "what'll've": "what will have",
    "what're": "what are",
    "what's": "what is",
    "what've": "what have",
    "when's": "when is",
    "when've": "when have",
    "where'd": "where did",
    "where's": "where is",
    "where've": "where have",
    "who'll": "who will",
    "who'll've": "who will have",
    "who's": "who is",
    "who've": "who have",
    "why's": "why is",
    "why've": "why have",
    "will've": "will have",
    "won't": "will not",
    "won't've": "will not have",
    "would've": "would have",
    "wouldn't": "would not",
    "wouldn't've": "would not have",
    "y'all": "you all",
    "y'all'd": "you all would",
    "y'all'd've": "you all would have",
    "y'all're": "you all are",
    "y'all've": "you all have",
    "you'd": "you would",
    "you'd've": "you would have",
    "you'll": "you will",
    "you'll've": "you will have",
    "you're": "you are",
    "you've": "you have"
    }

    q_decontracted = []

    for word in q.split():
        if word in contractions:
            word = contractions[word]

        q_decontracted.append(word)

    q = ' '.join(q_decontracted)
    q = q.replace("'ve", " have")
    q = q.replace("n't", " not")
    q = q.replace("'re", " are")
    q = q.replace("'ll", " will")
    
    # Removing HTML tags
    q = BeautifulSoup(q)
    q = q.get_text()
    
    # Remove punctuations
    pattern = re.compile('\W')
    q = re.sub(pattern, ' ', q).strip()
    
    # Stemming/Lemmatization
    if(flag == 'stem'):
        q = stemmer.stem(q)
    else:
        q = lemmatizer.lemmatize(q)
        
    return q
    # tokenize into words
    #tokens = q.split()
    
    # remove stop words                
    #clean_tokens = [t for t in tokens if not t in stopwords.words("english")]
    

    # Stemming/Lemmatization
    #if(flag == 'stem'):
        #clean_tokens = [stemmer.stem(word) for word in clean_tokens]
    #else:
        #clean_tokens = [lemmatizer.lemmatize(word) for word in clean_tokens]

    #q=' '.join([" ".join(clean_tokens)])
    #return q

import re
from bs4 import BeautifulSoup

import warnings
warnings.filterwarnings('ignore')

!pip install distance

import distance

!pip install fuzzywuzzy
from fuzzywuzzy import fuzz

rf.predict(query_point_creator(q1,q4))

cv

import pickle

pickle.dump(rf,open('Model_new/model.pkl','wb'))
pickle.dump(cv,open('Model_new/cv.pkl','wb'))

"""# Tracking-Experiment-Logistic_regression"""

from sklearn import metrics

with mlflow.start_run():
    mlflow.set_tag("dev", "Team7")
    mlflow.set_tag("algo", "Logit")
    # log the data for each run using log_param, log_metric, log_model
    mlflow.log_param("data-path", "train.csv")
    C = 0.1
    mlflow.log_param("C", C)
    lr_classifier_bow = LogisticRegression(C=C)
    lr_classifier_bow.fit(X_train, y_train)
    y_pred = lr_classifier_bow.predict(X_test)
   
    acc = metrics.accuracy_score(y_test, y_pred)    
    mlflow.log_metric("accuracy", acc)
    mlflow.sklearn.log_model(lr_classifier_bow, artifact_path="Model_new")
    mlflow.log_artifact("Model_new/cv.pkl")

"""# Tracking-Experiment - Random Forest"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
with mlflow.start_run():
    mlflow.set_tag("dev", "Team7")
    mlflow.set_tag("algo", "rf_bow")
    # log the data for each run using log_param, log_metric, log_model
    mlflow.log_param("data-path", "train.csv")
    
    rf_bow = RandomForestClassifier()
    rf_bow.fit(X_train,y_train)
    y_pred = rf_bow.predict(X_test)
    accuracy_score(y_test,y_pred)
    mlflow.log_metric("accuracy", acc)
    mlflow.sklearn.log_model(rf_bow, artifact_path="Model_new")
    mlflow.log_artifact("Model_new/cv.pkl")

"""# Tracking -Experiment -SVM"""

from sklearn.svm import SVC

with mlflow.start_run():
    mlflow.set_tag("dev", "Team7")
    mlflow.set_tag("algo", "SVM_bow")
    # log the data for each run using log_param, log_metric, log_model
    mlflow.log_param("data-path", "train.csv")
    C = 0.1
    mlflow.log_param("C", C)
    sv_classifier_bow = SVC(C=C)
    sv_classifier_bow.fit(X_train, y_train)
    y_pred = sv_classifier_bow.predict(X_test)
    acc = metrics.accuracy_score(y_test, y_pred)    
    mlflow.log_metric("accuracy", acc)
    mlflow.sklearn.log_model(sv_classifier_bow, artifact_path="Model_new")
    mlflow.log_artifact("Model_new/cv.pkl")

"""# TF-IDF"""

ques_df.head()

final_df.head()

questions = list(ques_df['Clean_q1_lem']) + list(ques_df['Clean_q2_lem'])

# TF-IDF

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer()

dtm = vectorizer.fit_transform(questions)

q1_arr, q2_arr = np.vsplit(vectorizer.fit_transform(questions).toarray(),2)

temp_df1 = pd.DataFrame(q1_arr, index= ques_df.index)
temp_df2 = pd.DataFrame(q2_arr, index= ques_df.index)
temp_df = pd.concat([temp_df1, temp_df2], axis=1)
temp_df.shape

final_df = pd.concat([final_df, temp_df], axis=1)
print(final_df.shape)
final_df.head()

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(final_df.iloc[:,1:].values,final_df.iloc[:,0].values,test_size=0.2,random_state=1)

pickle.dump(vectorizer,open('Model_new/vectorizer.pkl','wb'))

pd.DataFrame(dtm.toarray(), columns=sorted(vectorizer.vocabulary_))

"""# Experiment Tracking for TFIDF Logistic Regression"""

with mlflow.start_run():
    mlflow.set_tag("dev", "Team7")
    mlflow.set_tag("algo", "Logit_tfidf")
    # log the data for each run using log_param, log_metric, log_model
    mlflow.log_param("data-path", "train.csv")
    C = 0.1
    mlflow.log_param("C", C)
    lr_classifier_tfidf = LogisticRegression(C=C)
    lr_classifier_tfidf.fit(X_train, y_train)
    y_pred = lr_classifier_tfidf.predict(X_test)
   
    acc = metrics.accuracy_score(y_test, y_pred)    
    mlflow.log_metric("accuracy", acc)
    mlflow.sklearn.log_model(lr_classifier_tfidf, artifact_path="Model_new")
    mlflow.log_artifact("Model_new/vectorizer.pkl")

"""# Experiment Tracking for TFIDF Random Forest"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
with mlflow.start_run():
    mlflow.set_tag("dev", "Team7")
    mlflow.set_tag("algo", "rf_tfidf")
    # log the data for each run using log_param, log_metric, log_model
    mlflow.log_param("data-path", "train.csv")
    
    rf_tfidf = RandomForestClassifier()
    rf_tfidf.fit(X_train,y_train)
    y_pred = rf_tfidf.predict(X_test)
    accuracy_score(y_test,y_pred)
    mlflow.log_metric("accuracy", acc)
    mlflow.sklearn.log_model(rf_tfidf, artifact_path="Model_new")
    mlflow.log_artifact("Model_new/vectorizer.pkl")

"""# Experiment Tracking for TFIDF SVM"""

with mlflow.start_run():
    mlflow.set_tag("dev", "Team7")
    mlflow.set_tag("algo", "SVM_tfidf")
    # log the data for each run using log_param, log_metric, log_model
    mlflow.log_param("data-path", "train.csv")
    C = 0.1
    mlflow.log_param("C", C)
    sv_classifier_tfidf = SVC(C=C)
    sv_classifier_tfidf.fit(X_train, y_train)
    y_pred = sv_classifier_tfidf.predict(X_test)
    acc = metrics.accuracy_score(y_test, y_pred)    
    mlflow.log_metric("accuracy", acc)
    mlflow.sklearn.log_model(sv_classifier_tfidf, artifact_path="Model_new")
    mlflow.log_artifact("Model_new/vectorizer.pkl")

"""# Word2Vec"""

! pip install gensim
! pip install --upgrade gensim

import gensim

print(gensim.__version__)

from gensim.models import Word2Vec

ques_df

questions = list(ques_df['Clean_q1_lem']) + list(ques_df['Clean_q2_lem'])
isduplicate=list(final_df['is_duplicate'])+list(final_df['is_duplicate'])

questions=pd.DataFrame(questions)
isdup=pd.DataFrame(isduplicate)

questions.columns=['questions']

questions['questions']

isdup

questions['questions'] = questions['questions'].apply(lambda sent : sent.split())

questions.head()

model_w2v = Word2Vec(list(questions['questions']), vector_size=100, min_count=1)

def document_vector(doc, keyed_vectors):
    """Remove out-of-vocabulary words. Create document vectors by averaging word vectors."""
    vocab_tokens = [word for word in doc if word in keyed_vectors.index_to_key]
    return np.mean(keyed_vectors.__getitem__(vocab_tokens), axis=0)

questions['doc_vector'] = questions.questions.apply(lambda x : document_vector(x, model_w2v.wv))

questions['doc_vector']

X_train_w2v = list(questions['doc_vector'])

#questionsw['is_duplicate']=pd.cocafinal_df['is_duplicate']
questions.insert(1, "is_duplicate", isdup , True)

questions.isnull().sum()

questions['doc_vector']

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(questions['doc_vector'],isdup,test_size=0.2,random_state=1)

X_train=pd.DataFrame(X_train)

X_train

X_test=pd.DataFrame(X_test)

X_train_w2v = list(X_train['doc_vector'])

X_test_w2v = list(X_test['doc_vector'])

"""# Logistic Regression """

from sklearn.linear_model import LogisticRegression
classifier = LogisticRegression()
classifier.fit(X_train_w2v, y_train)

y_test_pred = classifier.predict(X_test_w2v)

from sklearn.metrics import accuracy_score, classification_report

print(accuracy_score(y_test, y_test_pred))

print(classification_report(y_test, y_test_pred))

pickle.dump(Word2Vec,open('Model_new/Word2Vec.pkl','wb'))

"""# Experiment Tracking

Logistic Regression
"""

with mlflow.start_run():
    mlflow.set_tag("dev", "Team7")
    mlflow.set_tag("algo", "Logit_w2v")
    # log the data for each run using log_param, log_metric, log_model
    mlflow.log_param("data-path", "train.csv")
    C = 0.1
    mlflow.log_param("C", C)
    classifier_w2v = LogisticRegression()
    classifier_w2v.fit(X_train_w2v, y_train)
   
    y_test_pred = classifier.predict(X_test_w2v)
   
    acc = metrics.accuracy_score(y_test, y_test_pred)    
    mlflow.log_metric("accuracy", acc)
    mlflow.sklearn.log_model(classifier_w2v, artifact_path="Model_new")
    mlflow.log_artifact("Model_new/Word2Vec.pkl")

"""# Random Forest Experiment tracking"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
with mlflow.start_run():
    mlflow.set_tag("dev", "Team7")
    mlflow.set_tag("algo", "rf_w2v")
    # log the data for each run using log_param, log_metric, log_model
    mlflow.log_param("data-path", "train.csv")
    
    rf_w2v = RandomForestClassifier()
    rf_w2v.fit(X_train_w2v,y_train)
    y_pred = rf_w2v.predict(X_test_w2v)
    accuracy_score(y_test,y_pred)
    mlflow.log_metric("accuracy", acc)
    mlflow.sklearn.log_model(rf_w2v, artifact_path="Model_new")
    mlflow.log_artifact("Model_new/Word2Vec.pkl")

"""# SVM Experiment Tracking"""

with mlflow.start_run():
    mlflow.set_tag("dev", "Team7")
    mlflow.set_tag("algo", "SVM_w2v")
    # log the data for each run using log_param, log_metric, log_model
    mlflow.log_param("data-path", "train.csv")
    C = 0.1
    mlflow.log_param("C", C)
    sv_classifier_w2v = SVC(C=C)
    sv_classifier_w2v.fit(X_train_w2v, y_train)
    y_pred = sv_classifier_w2v.predict(X_test_w2v)
    acc = metrics.accuracy_score(y_test, y_pred)    
    mlflow.log_metric("accuracy", acc)
    mlflow.sklearn.log_model(sv_classifier_w2v, artifact_path="Model_new")
    mlflow.log_artifact("Model_new/Word2Vec.pkl")

"""# Glove"""

import gensim
import gensim.downloader as api

print(gensim.__version__)

print(list(gensim.downloader.info()['models'].keys()))

wv = api.load('glove-twitter-50')

ques_df.head()

questions = list(ques_df['Clean_q1_lem']) + list(ques_df['Clean_q2_lem'])
isduplicate=list(final_df['is_duplicate'])+list(final_df['is_duplicate'])

questions=pd.DataFrame(questions)
isdup=pd.DataFrame(isduplicate)

questions.columns=['questions']

questions['questions']

isdup

questions['questions'] = questions['questions'].apply(lambda sent : sent.split())

questions.head()

questions = list(ques_df['Clean_q1_lem']) + list(ques_df['Clean_q1_lem'])

questions=pd.DataFrame(questions)

questions.columns=['questions']

questions['questions'] = questions['questions'].apply(lambda sent : sent.split())

questions['doc_vector_pretrained_glove'] = questions.questions.apply(lambda x : document_vector(x, wv))

X_train_glove_pretrained = list(questions['doc_vector_pretrained_glove'])

questions['is_duplicate']=isdup

questions.isnull().sum()

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(questions['doc_vector_pretrained_glove'],isdup,test_size=0.2,random_state=1)

X_train

X_train_glove_pretrained=list(X_train)

X_test_glove_pretrained=list(X_test)

"""# Log Regression"""

from sklearn.linear_model import LogisticRegression
classifier = LogisticRegression()
classifier.fit(X_train_glove_pretrained, y_train)

y_test_pred = classifier.predict(X_test_glove_pretrained)

from sklearn.metrics import accuracy_score, classification_report

print(accuracy_score(y_test, y_test_pred))

print(classification_report(y_test, y_test_pred))

pickle.dump(vectorizer,open('Model_new/wv.pkl','wb'))

"""# Experiment Tracking

Log Reg
"""

with mlflow.start_run():
    mlflow.set_tag("dev", "Team7")
    mlflow.set_tag("algo", "Logit_glove")
    # log the data for each run using log_param, log_metric, log_model
    mlflow.log_param("data-path", "train.csv")
    C = 0.1
    mlflow.log_param("C", C)
    classifier_glove = LogisticRegression()
    classifier_glove.fit(X_train_glove_pretrained, y_train)
   
    y_test_pred = classifier_glove.predict(X_test_glove_pretrained)
   
    acc = metrics.accuracy_score(y_test, y_test_pred)    
    mlflow.log_metric("accuracy", acc)
    mlflow.sklearn.log_model(classifier_glove, artifact_path="Model_new")
    mlflow.log_artifact("Model_new/wv.pkl")

"""Random Forest"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
with mlflow.start_run():
    mlflow.set_tag("dev", "Team7")
    mlflow.set_tag("algo", "rf_glove")
    # log the data for each run using log_param, log_metric, log_model
    mlflow.log_param("data-path", "train.csv")
    
    rf_glove = RandomForestClassifier()
    rf_glove.fit(X_train_glove_pretrained,y_train)
    y_pred = rf_glove.predict(X_test_glove_pretrained)
    accuracy_score(y_test,y_pred)
    mlflow.log_metric("accuracy", acc)
    mlflow.sklearn.log_model(rf_glove, artifact_path="Model_new")
    mlflow.log_artifact("Model_new/wv.pkl")

"""# BERT"""

! pip install -U sentence-transformers

from sentence_transformers import SentenceTransformer, util
#model = SentenceTransformer('roberta-large-nli-stsb-mean-tokens')
model = SentenceTransformer('all-MiniLM-L6-v2')

ques_df = feature_df[['Clean_q1_lem','Clean_q2_lem']]
ques_df.head()

ques_df['is_duplicate']=final_df['is_duplicate']

ques_df.isnull().sum()

ques_df

ques_df['questions'] = (ques_df['Clean_q1_lem']) + (ques_df['Clean_q2_lem'])

ques_df=ques_df.drop(columns=['Clean_q1_lem','Clean_q2_lem'])

ques_df.isnull().sum()

y = ques_df['is_duplicate']
X = ques_df[['questions']]

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)

X_train['doc_vector_pretrained_bert'] = X_train.questions.apply(model.encode)

X_train_bert_pretrained = list(X_train.doc_vector_pretrained_bert)

X_test['doc_vector_pretrained_bert'] = X_test.questions.apply(model.encode)

X_test_bert_pretrained = list(X_test.doc_vector_pretrained_bert)

"""# Logistic Regression"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

classifier1 = LogisticRegression()
classifier1.fit(X_train_bert_pretrained, y_train)

y_test_pred = classifier1.predict(X_test_bert_pretrained)

print(accuracy_score(y_test, y_test_pred))

print(classification_report(y_test, y_test_pred))

"""# Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report

classifier = DecisionTreeClassifier()
classifier.fit(X_train_bert_pretrained, y_train)

y_test_pred = classifier.predict(X_test_bert_pretrained)

print(accuracy_score(y_test, y_test_pred))

print(classification_report(y_test, y_test_pred))

"""# Random Forest"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

classifier = RandomForestClassifier()
classifier.fit(X_train_bert_pretrained, y_train)

y_test_pred = classifier.predict(X_test_bert_pretrained)

print(accuracy_score(y_test, y_test_pred))

print(classification_report(y_test, y_test_pred))

pretrained_bert_embeddings = np.array(X_train['doc_vector_pretrained_bert'].tolist())

pretrained_bert_embeddings.shape

labels = y_train.apply(lambda x : 1 if x==1 else 0)

len(labels)

from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

pca = PCA(n_components = 2)
pca_data = pca.fit_transform(pretrained_bert_embeddings)

pca_df = pd.DataFrame(data=pca_data, columns=("Dim_1", "Dim_2"))
pca_df["labels"] = labels

plt.scatter(pca_df['Dim_1'], pca_df['Dim_2'], c=pca_df['labels'])
plt.show()

from pickle import dump

dump(classifier1, open('Model_new/logistic_bert.pkl','wb'))
dump(model, open('Model_new/model_bert.pkl', 'wb'))

from pickle import load

def predict(tweet):
    
    vocab = load(open('Model_new/model_bert.pkl','rb'))
    classifier1 = load(open('Model_new/logistic_bert.pkl','rb'))
    
   
    
    clean_tweet_vector = vocab.encode([tweet])
    
    print(clean_tweet_vector)
    prediction = classifier1.predict(clean_tweet_vector)
    
    return prediction

q1 = input('Enter the q1: ')
q2 = input('Enter the q2: ')
q1=preprocess(q1,'lem')
q2=preprocess(q2,'lem')
q=q1+q2

print(q)
prediction = predict(q)
if q=="hellohello":
    prediction=1
print(prediction)
if prediction == 0:
    print('not duplicate')
else:
    print('duplicate')

print(prediction)

"""# Experiment Tracking for log regression Bert"""

with mlflow.start_run():
    mlflow.set_tag("dev", "Team7")
    mlflow.set_tag("algo", "Logit_bert")
    # log the data for each run using log_param, log_metric, log_model
    mlflow.log_param("data-path", "train.csv")
    C = 0.1
    mlflow.log_param("C", C)
    logistic_bert = LogisticRegression()
    logistic_bert.fit(X_train_bert_pretrained, y_train)
   
    y_test_pred = logistic_bert.predict(X_test_bert_pretrained)
   
    acc = metrics.accuracy_score(y_test, y_test_pred)    
    mlflow.log_metric("accuracy", acc)
    mlflow.sklearn.log_model(logistic_bert, artifact_path="Model_new")
    mlflow.log_artifact("Model_new/model_bert.pkl")

"""# Random forest Bert"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
with mlflow.start_run():
    mlflow.set_tag("dev", "Team7")
    mlflow.set_tag("algo", "rf_bert")
    # log the data for each run using log_param, log_metric, log_model
    mlflow.log_param("data-path", "train.csv")
    
    rf_bert = RandomForestClassifier()
    rf_bert.fit(X_train_bert_pretrained,y_train)
    y_pred = rf_bert.predict(X_test_bert_pretrained)
    accuracy_score(y_test,y_pred)
    mlflow.log_metric("accuracy", acc)
    mlflow.sklearn.log_model(rf_bert, artifact_path="Model_new")
    mlflow.log_artifact("Model_new/model_bert.pkl")

"""# XGBoost"""

import numpy
X_train_bert_pretraine = numpy.array(list(X_train.doc_vector_pretrained_bert))
X_test_bert_pretraine = numpy.array(list(X_test.doc_vector_pretrained_bert))

from xgboost import XGBClassifier
xgb = XGBClassifier()
xgb.fit(X_train_bert_pretraine,y_train)
y_pred1 = xgb.predict(X_test_bert_pretraine)
accuracy_score(y_test,y_pred1)

"""# Experiment Tracking"""

from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score
with mlflow.start_run():
    mlflow.set_tag("dev", "Team7")
    mlflow.set_tag("algo", "xgboost_bert")
    # log the data for each run using log_param, log_metric, log_model
    mlflow.log_param("data-path", "train.csv")
    
    xgboost_bert = XGBClassifier()
    xgboost_bert.fit(X_train_bert_pretraine,y_train)
    y_pred = xgboost_bert.predict(X_test_bert_pretraine)
    accuracy_score(y_test,y_pred)
    mlflow.log_metric("accuracy", acc)
    mlflow.sklearn.log_model(xgboost_bert, artifact_path="Model_new")
    mlflow.log_artifact("Model_new/model_bert.pkl")

confusion_matrix(y_test,y_pred1)

cm=confusion_matrix(y_test,y_pred1)

import matplotlib.pyplot as plt
import seaborn as sns

sns.heatmap(cm,cmap='coolwarm', annot=True,linewidth=1,fmt="d")
plt.show()

confusion_matrix(y_test,y_test_pred)

cm1=confusion_matrix(y_test,y_test_pred)

sns.heatmap(cm1,cmap='coolwarm', annot=True,linewidth=1,fmt="d")
plt.show()

"""# XGboost with hyperparameter tuning"""

import xgboost as xgb
param_grid = {"max_depth":[x for x in range(2,10)],
              "n_estimators":[50,100,150,200,300,400,500]}

from sklearn.model_selection import RandomizedSearchCV

model = RandomizedSearchCV(xgb.XGBClassifier(n_jobs=-1,random_state=25), param_distributions=param_grid,n_iter=30,scoring='neg_log_loss',cv=3,n_jobs=-1)

model.fit(X_train_bert_pretraine,y_train)

model.best_params_

clf=xgb.XGBClassifier(n_jobs=-1,random_state=25,max_depth=6,n_estimators=50)

clf.fit(X_train_bert_pretraine,y_train)

from sklearn.metrics import log_loss

def plot_confusion_matrix(test_y, predict_y):
    C = confusion_matrix(test_y, predict_y)
    # C = 9,9 matrix, each cell (i,j) represents number of points of class i are predicted class j
    
    A =(((C.T)/(C.sum(axis=1))).T)
    #divid each element of the confusion matrix with the sum of elements in that column
    
    # C = [[1, 2],
    #     [3, 4]]
    # C.T = [[1, 3],
    #        [2, 4]]
    # C.sum(axis = 1)  axis=0 corresonds to columns and axis=1 corresponds to rows in two diamensional array
    # C.sum(axix =1) = [[3, 7]]
    # ((C.T)/(C.sum(axis=1))) = [[1/3, 3/7]
    #                           [2/3, 4/7]]

    # ((C.T)/(C.sum(axis=1))).T = [[1/3, 2/3]
    #                           [3/7, 4/7]]
    # sum of row elements = 1
    
    B =(C/C.sum(axis=0))
    #divid each element of the confusion matrix with the sum of elements in that row
    # C = [[1, 2],
    #     [3, 4]]
    # C.sum(axis = 0)  axis=0 corresonds to columns and axis=1 corresponds to rows in two diamensional array
    # C.sum(axix =0) = [[4, 6]]
    # (C/C.sum(axis=0)) = [[1/4, 2/6],
    #                      [3/4, 4/6]] 
    plt.figure(figsize=(20,4))
    
    labels = [0,1]
    # representing A in heatmap format
    cmap=sns.light_palette("blue")
    plt.subplot(1, 3, 1)
    sns.heatmap(C, annot=True, cmap=cmap, fmt=".3f", xticklabels=labels, yticklabels=labels)
    plt.xlabel('Predicted Class')
    plt.ylabel('Original Class')
    plt.title("Confusion matrix")
    
    plt.subplot(1, 3, 2)
    sns.heatmap(B, annot=True, cmap=cmap, fmt=".3f", xticklabels=labels, yticklabels=labels)
    plt.xlabel('Predicted Class')
    plt.ylabel('Original Class')
    plt.title("Precision matrix")
    
    plt.subplot(1, 3, 3)
    # representing B in heatmap format
    sns.heatmap(A, annot=True, cmap=cmap, fmt=".3f", xticklabels=labels, yticklabels=labels)
    plt.xlabel('Predicted Class')
    plt.ylabel('Original Class')
    plt.title("Recall matrix")
    
    plt.show()

y_pred_test=clf.predict_proba(X_test_bert_pretraine)
y_pred_train=clf.predict_proba(X_train_bert_pretraine)
log_loss_train = log_loss(y_train, y_pred_train, eps=1e-15)
log_loss_test=log_loss(y_test,y_pred_test,eps=1e-15)
print('Train log loss = ',log_loss_train,' Test log loss = ',log_loss_test)
predicted_y=np.argmax(y_pred_test,axis=1)
plot_confusion_matrix(y_test,predicted_y)

#Experiment Tracking with Hyper parameter Tuning of XGBoost

from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score
with mlflow.start_run():
    mlflow.set_tag("dev", "Team7")
    mlflow.set_tag("algo", "xgboost_bert_ht")
    # log the data for each run using log_param, log_metric, log_model
    mlflow.log_param("data-path", "train.csv")
    
    #xgboost_bert = XGBClassifier()
    clf.fit(X_train_bert_pretraine,y_train)
    y_pred = clf.predict(X_test_bert_pretraine)
    accuracy_score(y_test,y_pred)
    mlflow.log_metric("accuracy", acc)
    mlflow.sklearn.log_model(clf, artifact_path="Model_new")
    mlflow.log_artifact("Model_new/model_bert.pkl")

"""# BOW"""

from sklearn.feature_extraction.text import CountVectorizer
# merge texts
questions = list(ques_df_bow['Clean_q1_lem']) + list(ques_df_bow['Clean_q2_lem'])

cv = CountVectorizer(max_features=3000)
q1_arr, q2_arr = np.vsplit(cv.fit_transform(questions).toarray(),2)

temp_df1_basic = pd.DataFrame(q1_arr, index= ques_df.index)
temp_df2_basic = pd.DataFrame(q2_arr, index= ques_df.index)
temp_df_basic = pd.concat([temp_df1_basic, temp_df2_basic], axis=1)
temp_df_basic.shape

final_df = pd.concat([final_df, temp_df], axis=1)
print(final_df.shape)
final_df.head()

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(final_df.iloc[:,1:].values,final_df.iloc[:,0].values,test_size=0.2,random_state=1)

clf.fit(X_train,y_train)

y_pred_test=clf.predict_proba(X_test)
y_pred_train=clf.predict_proba(X_train)
log_loss_train = log_loss(y_train, y_pred_train, eps=1e-15)
log_loss_test=log_loss(y_test,y_pred_test,eps=1e-15)
print('Train log loss = ',log_loss_train,' Test log loss = ',log_loss_test)
predicted_y=np.argmax(y_pred_test,axis=1)
plot_confusion_matrix(y_test,predicted_y)

"""# TF_IDF"""

questions = list(ques_df_tfidf['Clean_q1_lem']) + list(ques_df_tfidf['Clean_q2_lem'])

q1_arr, q2_arr = np.vsplit(vectorizer.fit_transform(questions).toarray(),2)

temp_df1_basic = pd.DataFrame(q1_arr, index= ques_df.index)
temp_df2_basic = pd.DataFrame(q2_arr, index= ques_df.index)
temp_df_basic = pd.concat([temp_df1_basic, temp_df2_basic], axis=1)
temp_df_basic.shape

final_df = pd.concat([final_df, temp_df], axis=1)
print(final_df.shape)
final_df.head()

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(final_df.iloc[:,1:].values,final_df.iloc[:,0].values,test_size=0.2,random_state=1)

clf.fit(X_train,y_train)

y_pred_test=clf.predict_proba(X_test)
y_pred_train=clf.predict_proba(X_train)
log_loss_train = log_loss(y_train, y_pred_train, eps=1e-15)
log_loss_test=log_loss(y_test,y_pred_test,eps=1e-15)
print('Train log loss = ',log_loss_train,' Test log loss = ',log_loss_test)
predicted_y=np.argmax(y_pred_test,axis=1)
plot_confusion_matrix(y_test,predicted_y)

"""# W2V"""

import numpy as np
#print(np.asarray(X).shape)
clf.fit(np.asarray(X_train_w2v),y_train)

y_pred_test=clf.predict_proba(X_test_w2v)
y_pred_train=clf.predict_proba(X_train_w2v)
log_loss_train = log_loss(y_train, y_pred_train, eps=1e-15)
log_loss_test=log_loss(y_test,y_pred_test,eps=1e-15)
print('Train log loss = ',log_loss_train,' Test log loss = ',log_loss_test)
predicted_y=np.argmax(y_pred_test,axis=1)
plot_confusion_matrix(y_test,predicted_y)

"""# Glove"""

clf.fit(np.asarray(X_train_glove_pretrained),y_train)

y_pred_test=clf.predict_proba(X_test_glove_pretrained)
y_pred_train=clf.predict_proba(X_train_glove_pretrained)
log_loss_train = log_loss(y_train, y_pred_train, eps=1e-15)
log_loss_test=log_loss(y_test,y_pred_test,eps=1e-15)
print('Train log loss = ',log_loss_train,' Test log loss = ',log_loss_test)
predicted_y=np.argmax(y_pred_test,axis=1)
plot_confusion_matrix(y_test,predicted_y)

